import asyncio
import json
from typing import Any, Dict
from dotenv import load_dotenv
from langchain_classic import hub
from langchain_classic.agents import AgentExecutor, create_openai_tools_agent
from langchain_mcp_adapters.client import MultiServerMCPClient
from langchain_ollama import ChatOllama
from loguru import logger

# åŠ è½½ .env æ–‡ä»¶ä¸­çš„ç¯å¢ƒå˜é‡ï¼Œoverride=True è¡¨ç¤ºè¦†ç›–å·²å­˜åœ¨çš„å˜é‡
load_dotenv(override=True)

# file_path è¡¨ç¤ºé…ç½®æ–‡ä»¶è·¯å¾„ï¼Œé»˜è®¤å€¼ä¸º "mcp.json"
# è¿”å›å­—å…¸ï¼ˆDictï¼‰ï¼Œé”®æ˜¯å­—ç¬¦ä¸²ï¼ˆæœåŠ¡å™¨æ ‡è¯†ï¼‰ï¼Œå€¼æ˜¯ä»»æ„ç±»å‹ï¼ˆæœåŠ¡å™¨é…ç½®ï¼‰
def load_servers(file_path: str = "mcp.json") -> Dict[str, Any]:
    """
    ä»æŒ‡å®šçš„ JSON æ–‡ä»¶ä¸­åŠ è½½ MCP æœåŠ¡å™¨é…ç½®ã€‚

    å‚æ•°:
        file_path (str): é…ç½®æ–‡ä»¶è·¯å¾„ï¼Œé»˜è®¤ä¸º "mcp.json"

    è¿”å›:
        Dict[str, Any]: åŒ…å« MCP æœåŠ¡å™¨é…ç½®çš„å­—å…¸ï¼Œè‹¥æ–‡ä»¶ä¸­æ²¡æœ‰ "mcpServers" é”®åˆ™è¿”å›ç©ºå­—å…¸
    """
    with open(file_path, "r", encoding="utf-8") as file:
        data = json.load(file) # åŠŸèƒ½ï¼šä½¿ç”¨Pythonçš„ json æ¨¡å—è§£ææ–‡ä»¶å†…å®¹ï¼›ä½œç”¨ï¼šå°†JSONæ ¼å¼çš„æ–‡æœ¬è½¬æ¢ä¸ºPythonå­—å…¸/åˆ—è¡¨ç­‰æ•°æ®ç»“æ„
        return data.get("mcpServers", {})


async def run_chat_loop() -> None:
    """
    å¯åŠ¨å¹¶è¿è¡Œä¸€ä¸ªåŸºäº MCP å·¥å…·çš„èŠå¤©ä»£ç†å¾ªç¯ã€‚

    è¯¥å‡½æ•°ä¼šï¼š
    1. åŠ è½½ MCP æœåŠ¡å™¨é…ç½®ï¼›
    2. åˆå§‹åŒ– MCP å®¢æˆ·ç«¯å¹¶è·å–å·¥å…·ï¼›
    3. åˆ›å»ºåŸºäº Ollama çš„è¯­è¨€æ¨¡å‹å’Œä»£ç†ï¼›
    4. å¯åŠ¨å‘½ä»¤è¡ŒèŠå¤©å¾ªç¯ï¼›
    5. åœ¨é€€å‡ºæ—¶æ¸…ç†èµ„æºã€‚

    è¿”å›:
        None
    """
    # 1ï¸âƒ£ åŠ è½½æœåŠ¡å™¨é…ç½®
    servers_cfg = load_servers() # é»˜è®¤å€¼ä¸º"mcp.json"

    # 2ï¸âƒ£ åˆå§‹åŒ– MCP å®¢æˆ·ç«¯å¹¶è·å–å·¥å…·
    mcp_client = MultiServerMCPClient(servers_cfg)
    tools = await mcp_client.get_tools()
    logger.info(f"âœ… å·²åŠ è½½ {len(tools)} ä¸ª MCP å·¥å…·ï¼š {[t.name for t in tools]}")

    # 3ï¸âƒ£ åˆå§‹åŒ–è¯­è¨€æ¨¡å‹ã€æç¤ºæ¨¡æ¿å’Œä»£ç†æ‰§è¡Œå™¨
    llm = ChatOllama(model="qwen3:14b", reasoning=False)
    prompt = hub.pull("hwchase17/openai-tools-agent")
    agent = create_openai_tools_agent(llm, tools, prompt)
    agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)

    # 4ï¸âƒ£ CLI èŠå¤©
    logger.info("\nğŸ¤– MCP Agent å·²å¯åŠ¨ï¼Œè¾“å…¥ 'quit' é€€å‡º")
    while True:
        user_input = input("\nYJYå¤§å¸…å“¥: ").strip()
        if user_input.lower() == "quit":
            break
        try:
            result = await agent_executor.ainvoke({"input": user_input})
            print(f"\nAI: {result['output']}")
        except Exception as exc:
            logger.error(f"\nâš ï¸  å‡ºé”™: {exc}")

    # 5ï¸âƒ£ æ¸…ç†
    logger.info("ğŸ§¹ ä¼šè¯å·²ç»“æŸï¼ŒBye YJY!")


if __name__ == "__main__":
    # å¯åŠ¨å¼‚æ­¥äº‹ä»¶å¾ªç¯å¹¶è¿è¡ŒèŠå¤©ä»£ç†
    asyncio.run(run_chat_loop())
