{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 为什么需要提示词模板\n",
    "\n",
    "在与大语言模型交互时，通常不会直接将用户的原始输入直接传递给大模型，而是会先进行一系列包装、组织和格式化操作。这样做的目的是：更清晰地表达用户意图，更好地利用模型能力。\n",
    "\n",
    "这套结构化的提示词构建方式，就是 LangChain 中的 提示词模板（PromptTemplate）。对于 LLM 应用来说，好的提示词就是成功的一半。更多提示词技巧可参考文档：https://www.cuiliangblog.cn/detail/section/228046450。\n",
    "\n",
    "LangChain 提示词官方文档参考：https://reference.langchain.com/python/langchain_core/prompts/"
   ],
   "id": "d5cca5bfbb2e7b11"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 提示词模板分类\n",
    "\n",
    "LangChain 提供了多种不同的提示词模板，下面介绍几种常用的提示词模板：\n",
    "\n",
    "PromptTemplate：文本生成模型提示词模板，用字符串拼接变量生成提示词\n",
    "\n",
    "ChatPromptTemplate：聊天模型提示词模板，适用于如 gpt-3.5-turbo、gpt-4 等聊天模型\n",
    "\n",
    "HumanMessagePromptTemplate：人类消息提示词模板\n",
    "\n",
    "SystemMessagePromptTemplate：系统消息提示词模板\n",
    "\n",
    "FewShotPromptTemplate：少样本学习提示词模板， 构建一个 Prompt，其中包含多个 示例，可以 自动将这些示例格式化并插入到主 Prompt 中 。\n",
    "\n",
    "PipelinePrompt：管道提示词模板，用于把几个提示词组合在一起使用。"
   ],
   "id": "447f7b1ea43a971b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 提示词模板类继承关系\n",
    "\n",
    "分析LangChain源码可以可知，在 LangChain 的类结构中，顶层基类是 BasePromptTemplate，用于定义Prompt 模板系统必须实现的核心方法，而StringPromptTemplate 和 BaseChatPromptTemplate两个子类分别继承。\n",
    "\n",
    "接入聊天模型时需继承BaseChatPromptTemplate；而文本生成模型则继承StringPromptTemplate 。"
   ],
   "id": "91c5a9319bcb85ee"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 2.文本提示词模板\n",
    "\n",
    "PromptTemplate 针对文本生成模型的提示词模板，也是LangChain提供的最基础的模板，通过格式化字符串生成提示词，在执行invoke时将变量格式化到提示词模板中\n",
    "\n",
    "主要参数：\n",
    "\n",
    "template：定义提示词模板的字符串，其中包含文本和变量占位符（如{name}） ；\n",
    "\n",
    "input_variables： 列表，指定了模板中使用的变量名称，在调用模板时被替换；\n",
    "\n",
    "partial_variables：字典，用于定义模板中一些固定的变量名。这些值不需要再每次调用时被替换。\n",
    "\n",
    "函数介绍：\n",
    "\n",
    "format()：给input_variables变量赋值，并返回提示词。利用format() 进行格式化时就一定要赋值，否则会报错。当在template中未设置input_variables，则会自动忽略。"
   ],
   "id": "881f76e12e6e48c9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-22T07:40:21.927309Z",
     "start_time": "2025-11-22T07:40:21.674418Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# 创建一个PromptTemplate对象，用于生成格式化的提示词模板\n",
    "# 该模板包含两个变量：role（角色）和question（问题）\n",
    "template = PromptTemplate(template=\"你是一个专业的{role}工程师，请回答我的问题给出回答，我的问题是：{question}\",\n",
    "                        input_variables=['role', 'question'])\n",
    "\n",
    "# 使用模板格式化具体的提示词内容\n",
    "# 将role替换为\"python开发\"，question替换为\"冒泡排序怎么写？\"\n",
    "prompt = template.format(role=\"python开发\",question=\"冒泡排序怎么写？\")\n",
    "\n",
    "# 输出格式化后的提示词内容\n",
    "print(prompt)\n",
    "print(type(prompt))"
   ],
   "id": "602397083729cd18",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "你是一个专业的python开发工程师，请回答我的问题给出回答，我的问题是：冒泡排序怎么写？\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 2.1调用from_template(常用)",
   "id": "8a3769910ad5bf59"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-22T07:41:36.853026Z",
     "start_time": "2025-11-22T07:41:36.850070Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# 创建一个PromptTemplate对象，用于生成格式化的提示词模板\n",
    "# 模板包含两个占位符：{role}表示角色，{question}表示问题\n",
    "template = PromptTemplate.from_template(\"你是一个专业的{role}工程师，请回答我的问题给出回答，我的问题是：{question}\")\n",
    "\n",
    "# 使用指定的角色和问题参数来格式化模板，生成最终的提示词字符串\n",
    "# role: 工程师角色描述\n",
    "# question: 具体的技术问题\n",
    "prompt = template.format(role=\"python开发\",question=\"冒泡排序怎么写？\")\n",
    "\n",
    "# 输出生成的提示词\n",
    "print(prompt)\n",
    "print(type(prompt))"
   ],
   "id": "df9b4633a2681f36",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "你是一个专业的python开发工程师，请回答我的问题给出回答，我的问题是：冒泡排序怎么写？\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 2.2部分提示词模板\n",
    "\n",
    "部分提示词，顾名思义就是允许你预先固定部分变量，而保留其他变量在后续动态填充。例如：先预设系统参数，然后等用户输入后再补齐提示词模板。"
   ],
   "id": "b0ec1ae1a841af06"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-22T07:46:29.105713Z",
     "start_time": "2025-11-22T07:46:29.102022Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from datetime import datetime\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# 创建一个包含时间变量的模板，时间变量使用partial_variables预设为当前时间\n",
    "# 然后格式化问题生成最终提示词\n",
    "template1 = PromptTemplate.from_template(\"现在时间是：{time},请对我的问题给出答案，我的问题是：{question}\",\n",
    "                                         partial_variables={\"time\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")})\n",
    "prompt1 = template1.format(question=\"今天是几号？\")\n",
    "print(prompt1)\n",
    "\n",
    "# 创建一个包含时间变量的模板，通过partial方法预设时间变量为当前时间\n",
    "# 然后格式化问题生成最终提示词\n",
    "template2 = PromptTemplate.from_template(\"现在时间是：{time},请对我的问题给出答案，我的问题是：{question}\")\n",
    "partial = template2.partial(time=datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "prompt2 = partial.format(question=\"今天是几号？\")\n",
    "print(prompt2)\n"
   ],
   "id": "e9d1e49d40d4528b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "现在时间是：2025-11-22 15:46:29,请对我的问题给出答案，我的问题是：今天是几号？\n",
      "现在时间是：2025-11-22 15:46:29,请对我的问题给出答案，我的问题是：今天是几号？\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 2.3组合提示词模板\n",
    "通过将多个子提示（Prompt）按一定逻辑顺序或层级组合起来，形成一个复杂任务的整体 Prompt。例如实现多消息对话、多阶段任务、多输入源组合等场景。"
   ],
   "id": "4a6ce50ce7db405e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-22T08:28:58.504079Z",
     "start_time": "2025-11-22T08:28:58.500971Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# 创建一个PromptTemplate模板，用于生成介绍某个主题的提示词\n",
    "# 该模板包含两个占位符：topic（主题）和length（字数限制）\n",
    "template1 = PromptTemplate.from_template(\"请用一句话介绍{topic}，要求通俗易懂\\n\") + \"内容不超过{length}个字\"\n",
    "# 使用format方法填充模板中的占位符，生成具体的提示词\n",
    "prompt1 = template1.format(topic=\"LangChain\", length=20)\n",
    "print(prompt1)\n",
    "\n",
    "# 分别创建两个独立的PromptTemplate模板\n",
    "prompt_a = PromptTemplate.from_template(\"请用一句话介绍{topic}，要求通俗易懂\\n\")\n",
    "prompt_b = PromptTemplate.from_template(\"内容不超过{length}个字\")\n",
    "# 将两个模板进行拼接组合\n",
    "prompt_all = prompt_a + prompt_b\n",
    "# 填充组合后模板的占位符，生成最终的提示词\n",
    "prompt2 = prompt_all.format(topic=\"LangChain\", length=20)\n",
    "print(prompt2)"
   ],
   "id": "cb77310b8e0e1f79",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "请用一句话介绍LangChain，要求通俗易懂\n",
      "内容不超过20个字\n",
      "请用一句话介绍LangChain，要求通俗易懂\n",
      "内容不超过20个字\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 2.4提示词方法\n",
    "上述的代码示例中，我们使用了format方法，除了format方法能够格式化提示词模板，invoke()和partial()方法也可以做到，以下是它们的作用：\n",
    "\n",
    "invoke：格式化提示词模板为PromptValue\n",
    "\n",
    "format：格式化提示词模板为字符串\n",
    "\n",
    "partial：格式化提示词模板为一个新的提示词模板，可以继续进行格式化"
   ],
   "id": "9642d24f667c901e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 2.4.1format\n",
    "format() 方法用法如下，将 question 参数格式化到提示词模板中，返回一个字符串："
   ],
   "id": "fa845e3fe28fb2f2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-22T08:31:12.930189Z",
     "start_time": "2025-11-22T08:31:12.927606Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# 创建一个PromptTemplate对象，用于生成格式化的提示词模板\n",
    "# 模板包含两个占位符：{role}表示角色，{question}表示问题\n",
    "template = PromptTemplate.from_template(\"你是一个专业的{role}工程师，请回答我的问题给出回答，我的问题是：{question}\")\n",
    "\n",
    "# 使用指定的角色和问题参数来格式化模板，生成最终的提示词字符串\n",
    "# role: 工程师角色描述\n",
    "# question: 具体的技术问题\n",
    "prompt = template.format(role=\"python开发\",question=\"冒泡排序怎么写？\")\n",
    "\n",
    "# 输出生成的提示词\n",
    "print(prompt)\n",
    "print(type(prompt))"
   ],
   "id": "2a5bdc9632b7260c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "你是一个专业的python开发工程师，请回答我的问题给出回答，我的问题是：冒泡排序怎么写？\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 2.4.2partial\n",
    "partial()方法用法如下，可以格式化部分变量，并且继续返回一个模板，通常在部分提示词模板场景下使用"
   ],
   "id": "6fa4aa0ccb808c94"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-22T08:34:14.214662Z",
     "start_time": "2025-11-22T08:34:14.211420Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# 创建模板对象，定义提示词模板格式\n",
    "# 模板包含两个占位符：role（角色）和 question（问题）\n",
    "template = PromptTemplate.from_template(\"你是一个专业的{role}工程师，请回答我的问题给出回答，我的问题是：{question}\")\n",
    "\n",
    "# 使用partial方法固定role参数为\"python开发\"\n",
    "# 返回一个新的模板对象，其中role参数已被绑定\n",
    "partial = template.partial(role=\"python开发\")\n",
    "\n",
    "# 打印partial对象及其类型信息\n",
    "print(partial)\n",
    "print(type(partial))\n",
    "\n",
    "# 使用format方法填充question参数，生成最终的提示词字符串\n",
    "# 此时所有占位符都已填充完毕，返回完整的提示词文本\n",
    "prompt = partial.format(question=\"冒泡排序怎么写？\")\n",
    "\n",
    "# 输出生成的提示词\n",
    "print(prompt)\n",
    "print(type(prompt))"
   ],
   "id": "c44167a588599477",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['question'] input_types={} partial_variables={'role': 'python开发'} template='你是一个专业的{role}工程师，请回答我的问题给出回答，我的问题是：{question}'\n",
      "<class 'langchain_core.prompts.prompt.PromptTemplate'>\n",
      "你是一个专业的python开发工程师，请回答我的问题给出回答，我的问题是：冒泡排序怎么写？\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 2.4.3invoke\n",
    "invoke() 是 LangChain Expression Language（LCEL 的统一执行入口，用于执行任意可运行对象（Runnable ）。返回的是一个 PromptValue 对象，可以用 .to_string() 或 .to_messages() 查看内容。"
   ],
   "id": "108743a9f7b35052"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-22T08:37:40.949256Z",
     "start_time": "2025-11-22T08:37:40.945988Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# 创建一个PromptTemplate对象，用于生成格式化的提示词模板\n",
    "# 模板中包含两个占位符：{role}表示角色，{question}表示问题\n",
    "template = PromptTemplate.from_template(\"你是一个专业的{role}工程师，请回答我的问题给出回答，我的问题是：{question}\")\n",
    "\n",
    "# 使用invoke方法填充模板中的占位符，生成具体的提示词\n",
    "# 参数：字典类型，包含role和question两个键值对\n",
    "# 返回值：PromptValue对象，包含了格式化后的提示词\n",
    "prompt = template.invoke({\"role\": \"python开发\", \"question\": \"冒泡排序怎么写？\"})\n",
    "\n",
    "# 打印PromptValue对象及其类型\n",
    "print(prompt)\n",
    "print(type(prompt))\n",
    "\n",
    "# 将PromptValue对象转换为字符串并打印\n",
    "# to_string()方法将PromptValue转换为可读的字符串格式\n",
    "print(prompt.to_string())\n",
    "print(type(prompt.to_string()))\n"
   ],
   "id": "5d7c7b823593d458",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text='你是一个专业的python开发工程师，请回答我的问题给出回答，我的问题是：冒泡排序怎么写？'\n",
      "<class 'langchain_core.prompt_values.StringPromptValue'>\n",
      "你是一个专业的python开发工程师，请回答我的问题给出回答，我的问题是：冒泡排序怎么写？\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 3.对话提示词模板\n",
    "ChatPromptTemplate 是专为聊天模型（如 gpt-3.5-turbo、gpt-4 等）设计的提示词模板，它支持构造多轮对话的消息结构，每条消息可指定角色（如系统、用户、AI）。\n",
    "\n",
    "特点：\n",
    "\n",
    "支持 System / Human / AI 等不同角色的消息模板\n",
    "对话历史维护\n",
    "参数类型：列表参数格式是tuple类型（ role :str content :str 组合最常用）\n",
    "\n",
    "元组的格式为：(role: str | type, content: str | list[dict] | list[object])\n",
    "\n",
    "其中 role 是：字符串（如 “system” 、“human” 、“ai” ）"
   ],
   "id": "649a83fde8b7a9dc"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 3.1创建提示词",
   "id": "9303c56c7fa04d58"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 3.1.1使用构造方法",
   "id": "61fc48a4d20e5608"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-22T08:43:24.577500Z",
     "start_time": "2025-11-22T08:43:24.563264Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# 创建聊天提示模板，包含系统角色设定、用户询问和AI回答的对话历史\n",
    "# 以及用户当前输入的占位符\n",
    "prompt_template = ChatPromptTemplate([\n",
    "    (\"system\", \"你是一个AI助手，你的名字是{name}\"),\n",
    "    (\"human\", \"你能做什么事\"),\n",
    "    (\"ai\", \"我可以陪你聊天，讲笑话，写代码\"),\n",
    "    (\"human\", \"{user_input}\"),\n",
    "])\n",
    "\n",
    "# 使用指定的参数格式化提示模板，生成最终的提示字符串\n",
    "# name: AI助手的名称\n",
    "# user_input: 用户的当前输入\n",
    "prompt = prompt_template.format(name=\"小张\", user_input=\"你可以做什么\")\n",
    "print(prompt)"
   ],
   "id": "d1e9ce85e429e57f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System: 你是一个AI助手，你的名字是小张\n",
      "Human: 你能做什么事\n",
      "AI: 我可以陪你聊天，讲笑话，写代码\n",
      "Human: 你可以做什么\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 3.1.2调用form_message(常用)\n",
    "代码示例如下，提示词模板中包含两条消息，第一条是系统消息，无需做提示词渲染，第二条是人类消息，在执行invoke时，需要把变量question渲染进去。"
   ],
   "id": "b62fe464f2fcecaa"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-22T08:45:04.873862Z",
     "start_time": "2025-11-22T08:45:04.870744Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# 创建聊天提示模板，包含系统角色设定和用户问题格式\n",
    "# 系统消息定义了AI的角色，人类消息定义了问题的输入格式\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"你是一个{role}，请回答我提出的问题\"),\n",
    "    (\"human\", \"请回答:{question}\")\n",
    "])\n",
    "\n",
    "# 使用指定的角色和问题参数填充模板，生成具体的提示内容\n",
    "# role: 指定AI扮演的角色\n",
    "# question: 用户提出的具体问题\n",
    "prompt_value = chat_prompt.invoke({\"role\": \"python开发工程师\", \"question\": \"冒泡排序怎么写\"})\n",
    "\n",
    "# 输出生成的提示内容\n",
    "print(prompt_value)\n",
    "print(prompt_value.to_string())"
   ],
   "id": "f304f21655315f25",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "messages=[SystemMessage(content='你是一个python开发工程师，请回答我提出的问题', additional_kwargs={}, response_metadata={}), HumanMessage(content='请回答:冒泡排序怎么写', additional_kwargs={}, response_metadata={})]\n",
      "System: 你是一个python开发工程师，请回答我提出的问题\n",
      "Human: 请回答:冒泡排序怎么写\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 3.2提示词方法\n",
    "除了之前在 PromptTemplate介绍的 format、partial、invoke外，还有 format_messages 和 format_prompt方法。"
   ],
   "id": "58a2eb6bcd12d144"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 3.2.1format_messages\n",
    "作用：将模板变量替换后，直接生成 消息列表（List[BaseMessage]），一般包含：SystemMessage,HumanMessage,AIMessage\n",
    "\n",
    "常用场景：用于手动查看或调试 Prompt 的最终“消息结构”，或者自己拼接进 Chain。\n",
    "\n",
    "代码如下"
   ],
   "id": "3d38097efb96dbee"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-22T09:12:16.087301Z",
     "start_time": "2025-11-22T09:12:16.084070Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# 创建聊天提示模板，包含系统角色设定和用户问题格式\n",
    "# 系统消息定义了AI助手的角色，人类消息定义了用户问题的格式\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"你是一个{role}，请回答我提出的问题\"),\n",
    "    (\"human\", \"请回答:{question}\")\n",
    "])\n",
    "\n",
    "# 格式化聊天提示模板，填充角色和问题参数\n",
    "# 参数role: 指定AI助手的角色身份\n",
    "# 参数question: 用户提出的具体问题\n",
    "# 返回值: 格式化后的消息列表\n",
    "prompt_value = chat_prompt.format_messages(role=\"python开发工程师\", question=\"冒泡排序怎么写\")\n",
    "\n",
    "# 打印格式化后的提示消息\n",
    "print(prompt_value)"
   ],
   "id": "bdaa8e7044a11c81",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SystemMessage(content='你是一个python开发工程师，请回答我提出的问题', additional_kwargs={}, response_metadata={}), HumanMessage(content='请回答:冒泡排序怎么写', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#  3.2.2format_prompt\n",
    "作用：生成一个 PromptValue 对象，这是一种抽象层次更高的封装。\n",
    "\n",
    "对于 PromptTemplate（单纯文本），返回 StringPromptValue\n",
    "\n",
    "对于 ChatPromptTemplate（对话模板），返回 ChatPromptValue\n",
    "\n",
    "PromptValue 有两个常用方法：\n",
    "\n",
    ".to_string() → 转成文本\n",
    "\n",
    ".to_messages() → 转成消息列表（同上）\n",
    "\n",
    "返回值：PromptValue 对象\n",
    "\n",
    "代码如下"
   ],
   "id": "9c53344fe066108d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-22T09:15:59.183143Z",
     "start_time": "2025-11-22T09:15:59.179756Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# 创建聊天提示模板，包含系统角色设定和用户问题格式\n",
    "# 该模板定义了两个消息：系统消息用于设定AI助手的角色，人类消息用于接收用户的具体问题\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"你是一个{role}，请回答我提出的问题\"),\n",
    "    (\"human\", \"请回答:{question}\")\n",
    "])\n",
    "\n",
    "# 使用指定的角色和问题参数格式化聊天提示模板\n",
    "# role: 指定AI助手的角色身份\n",
    "# question: 用户提出的具体问题\n",
    "# 返回格式化后的提示对象，可用于后续的模型调用\n",
    "prompt = chat_prompt.format_prompt(role=\"python开发工程师\", question=\"冒泡排序怎么写\")\n",
    "\n",
    "# 打印格式化后的提示内容\n",
    "print(prompt)\n",
    "\n",
    "# 将提示转换为消息列表并打印\n",
    "print(prompt.to_messages())"
   ],
   "id": "fea1756f28aef98a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "messages=[SystemMessage(content='你是一个python开发工程师，请回答我提出的问题', additional_kwargs={}, response_metadata={}), HumanMessage(content='请回答:冒泡排序怎么写', additional_kwargs={}, response_metadata={})]\n",
      "[SystemMessage(content='你是一个python开发工程师，请回答我提出的问题', additional_kwargs={}, response_metadata={}), HumanMessage(content='请回答:冒泡排序怎么写', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 3.3实例化参数类型\n",
    "前面讲了ChatPromptTemplate的两种创建方式。我们看到不管使用构造方法，参数类型都是列表类型。参数除了是列表类型，列表的元素可以是字符串、字典、字符串构成的元组、消息类型、提示词模板类型、消息提示词模板类型等"
   ],
   "id": "bc209e3066ec6516"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 3.3.1str 类型\n",
    "列表参数格式是str类型（不推荐），因为默认都是HumanMessage。\n",
    "\n",
    "代码如下"
   ],
   "id": "e3edda945271f8d6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-22T09:18:06.864600Z",
     "start_time": "2025-11-22T09:18:06.861411Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# 创建聊天提示模板，用于构建AI助手的对话上下文\n",
    "# 该模板包含两个消息：AI助手的自我介绍和用户问题\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    \"你是AI助手，你的名字叫{name}。\",\n",
    "    \"请问：{question}\"\n",
    "])\n",
    "\n",
    "# 格式化聊天提示模板，填充具体的助手名称和问题内容\n",
    "# 参数name: AI助手的名字\n",
    "# 参数question: 用户提出的问题\n",
    "# 返回值: 格式化后的消息列表\n",
    "message = chat_prompt.format_messages(name=\"亮仔\", question=\"什么是LangChain\")\n",
    "\n",
    "# 打印格式化后的消息内容\n",
    "print(message)"
   ],
   "id": "71df7f95a34cb504",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HumanMessage(content='你是AI助手，你的名字叫亮仔。', additional_kwargs={}, response_metadata={}), HumanMessage(content='请问：什么是LangChain', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 3.3.2dict 类型\n",
    "列表参数格式是dict类型，代码如下:"
   ],
   "id": "39b536470859d2a3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-22T09:21:08.322892Z",
     "start_time": "2025-11-22T09:21:08.320021Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# 创建聊天提示模板，用于构建AI助手的对话上下文\n",
    "# 该模板包含两个消息：AI助手的自我介绍和用户问题\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    {\"role\": \"system\", \"content\": \"你是AI助手，你的名字叫{name}。\"},\n",
    "    {\"role\": \"user\", \"content\": \"请问：{question}\"}\n",
    "\n",
    "])\n",
    "\n",
    "# 格式化聊天提示模板，填充具体的助手名称和问题内容\n",
    "# 参数name: AI助手的名字\n",
    "# 参数question: 用户提出的问题\n",
    "# 返回值: 格式化后的消息列表\n",
    "message = chat_prompt.format_messages(name=\"亮仔\", question=\"什么是LangChain\")\n",
    "\n",
    "# 打印格式化后的消息内容\n",
    "print(message)"
   ],
   "id": "10874f5818702314",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SystemMessage(content='你是AI助手，你的名字叫亮仔。', additional_kwargs={}, response_metadata={}), HumanMessage(content='请问：什么是LangChain', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 3.3.3message 类型\n",
    "System/Human/AIMessage 是 langchain 中用于构建不同角色的一个类。它通常用于创建聊天消息的一部分，特别是当你构建一个多轮对话的 prompt 模板时，区分系统、AI、和人类消息。\n",
    "代码如下"
   ],
   "id": "deebb412d37cb7ec"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-22T09:22:39.070564Z",
     "start_time": "2025-11-22T09:22:39.067701Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# 创建聊天提示模板，用于构建AI助手的对话上下文\n",
    "# 该模板包含两个消息：AI助手的自我介绍和用户问题\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    SystemMessage(content=\"你是AI助手，你的名字叫{name}。\"),\n",
    "    HumanMessage(content=\"请问：{question}\")\n",
    "])\n",
    "\n",
    "# 格式化聊天提示模板，填充具体的助手名称和问题内容\n",
    "# 参数name: AI助手的名字\n",
    "# 参数question: 用户提出的问题\n",
    "# 返回值: 格式化后的消息列表\n",
    "message = chat_prompt.format_messages(name=\"亮仔\", question=\"什么是LangChain\")\n",
    "\n",
    "# 打印格式化后的消息内容\n",
    "print(message)"
   ],
   "id": "4987f4248c52a794",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SystemMessage(content='你是AI助手，你的名字叫{name}。', additional_kwargs={}, response_metadata={}), HumanMessage(content='请问：{question}', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 3.3.4BaseChatPromptTemplate 类型\n",
    "使用 BaseChatPromptTemplate，可以理解为ChatPromptTemplate里嵌套了ChatPromptTemplate。"
   ],
   "id": "25bbf7de3e7c3abd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-22T09:24:12.260431Z",
     "start_time": "2025-11-22T09:24:12.257517Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# 创建系统消息模板，用于定义AI助手的身份信息\n",
    "prompt_template1 = ChatPromptTemplate.from_messages([(\"system\", \"你是AI助手，你的名字叫{name}。\")])\n",
    "\n",
    "# 创建人类消息模板，用于定义用户提问的格式\n",
    "prompt_template2 = ChatPromptTemplate.from_messages([(\"human\", \"请问：{question}\")])\n",
    "\n",
    "# 将系统消息模板和人类消息模板组合成完整的对话模板\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    prompt_template1,\n",
    "    prompt_template2\n",
    "])\n",
    "\n",
    "# 使用指定的参数格式化消息模板，生成实际的消息内容\n",
    "message = chat_prompt.format_messages(name=\"亮仔\", question=\"什么是LangChain\")\n",
    "\n",
    "# 打印生成的消息内容\n",
    "print(message)"
   ],
   "id": "65e34559550edec",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SystemMessage(content='你是AI助手，你的名字叫亮仔。', additional_kwargs={}, response_metadata={}), HumanMessage(content='请问：什么是LangChain', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 3.3.5BaseMessagePromptTemplate 类型\n",
    "LangChain提供不同类型的MessagePromptTemplate。最常用的是SystemMessagePromptTemplate 、HumanMessagePromptTemplate 和AIMessagePromptTemplate ，分别创建系统消息、人工消息和AI消息，它们是ChatMessagePromptTemplate的特定角色子类。\n",
    "\n",
    "基本概念：\n",
    "\n",
    "HumanMessagePromptTemplate，专用于生成用户消息（HumanMessage） 的模板类，是ChatMessagePromptTemplate的特定角色子类。\n",
    "\n",
    "本质：预定义了 role=“human” 的 MessagePromptTemplate，且无需无需手动指定角色\n",
    "\n",
    "模板化：支持使用变量占位符，可以在运行时填充具体值\n",
    "\n",
    "格式化：能够将模板与输入变量结合生成最终的聊天消息\n",
    "\n",
    "输出类型：生成 HumanMessage 对象（ content + role=“human” ）\n",
    "\n",
    "设计目的 ：简化用户输入消息的模板化构造，避免重复定义角色\n",
    "\n",
    "SystemMessagePromptTemplate、AIMessagePromptTemplate：类似于上面，不再赘述\n",
    "\n",
    "ChatMessagePromptTemplate，用于构建聊天消息的模板。它允许你创建可重用的消息模板，这些模板可以动态地插入变量值来生成最终的聊天消息\n",
    "\n",
    "角色指定：可以为每条消息指定角色（如 “system”、“human”、“ai”） 等，角色灵活。\n",
    "\n",
    "模板化：支持使用变量占位符，可以在运行时填充具体值\n",
    "\n",
    "格式化：能够将模板与输入变量结合生成最终的聊天消息\n",
    "\n",
    "示例代码如下"
   ],
   "id": "66fe17476e7c75ad"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-22T09:28:57.852958Z",
     "start_time": "2025-11-22T09:28:57.849037Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "\n",
    "# 创建系统消息模板，用于定义AI助手的身份信息\n",
    "system_prompt=SystemMessagePromptTemplate.from_template(\"你是AI助手，你的名字叫{name}。\")\n",
    "\n",
    "# 创建人类消息模板，用于定义用户提问的格式\n",
    "human_prompt = HumanMessagePromptTemplate.from_template(\"请回答：{question}\")\n",
    "\n",
    "# 创建具体的系统消息和人类消息实例\n",
    "system_msg = SystemMessage(content=\"你是AI工程师\")\n",
    "human_msg = HumanMessage(content=\"你好\")\n",
    "\n",
    "# 创建嵌套的消息模板，包含预定义的系统和人类消息\n",
    "nested_prompt = ChatPromptTemplate.from_messages([system_msg, human_msg])\n",
    "\n",
    "# 构建完整的聊天提示模板，组合了模板和具体消息\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    system_prompt,\n",
    "    human_prompt,\n",
    "    system_msg,\n",
    "    human_msg,\n",
    "    nested_prompt\n",
    "])\n",
    "\n",
    "# 格式化消息并打印结果\n",
    "message = chat_prompt.format_messages(name=\"亮仔\", question=\"什么是LangChain?\")\n",
    "print(message)\n"
   ],
   "id": "b56a66ce97e3f125",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SystemMessage(content='你是AI助手，你的名字叫亮仔。', additional_kwargs={}, response_metadata={}), HumanMessage(content='请回答：什么是LangChain?', additional_kwargs={}, response_metadata={}), SystemMessage(content='你是AI工程师', additional_kwargs={}, response_metadata={}), HumanMessage(content='你好', additional_kwargs={}, response_metadata={}), SystemMessage(content='你是AI工程师', additional_kwargs={}, response_metadata={}), HumanMessage(content='你好', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 4.少量样本提示词模板",
   "id": "f39081fbe919c74c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 4.1FewShotPromptTemplate(看4.2即可)\n",
    "FewShotPromptTemplate 用于：\n",
    "\n",
    "构建一个 Prompt，其中包含多个 示例（examples）；\n",
    "\n",
    "自动将这些示例格式化并插入到主 Prompt 中；\n",
    "\n",
    "实现 Few-Shot Prompting 方式，以增强大模型在特定任务（如分类、问答、翻译等）上的表现。\n",
    "\n",
    "它通常由以下几部分构成：\n",
    "\n",
    "examples：少量的人工示例（dict 列表）；\n",
    "\n",
    "example_prompt：如何格式化每个示例（使用 PromptTemplate）；\n",
    "\n",
    "prefix：示例之前的文字说明（可选）；\n",
    "\n",
    "suffix：用户真正的问题模板；\n",
    "\n",
    "input_variables：最终 suffix 中需要传入的变量。\n",
    "\n",
    "假设开发一个提取语句城市名称的AI："
   ],
   "id": "d6455dd8f28d2360"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-22T09:33:14.956876Z",
     "start_time": "2025-11-22T09:33:14.954028Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.prompts import FewShotPromptTemplate, PromptTemplate\n",
    "\n",
    "# 几个示例，说明模型该如何输出\n",
    "examples = [\n",
    "    {\"input\": \"北京下雨吗\", \"output\": \"北京\"},\n",
    "    {\"input\": \"上海热吗\", \"output\": \"上海\"},\n",
    "]\n",
    "\n",
    "# 定义如何格式化每个示例\n",
    "example_prompt = PromptTemplate(\n",
    "    input_variables=[\"input\", \"output\"],\n",
    "    template=\"输入：{input}\\n输出：{output}\"\n",
    ")\n",
    "\n",
    "# 构建 FewShotPromptTemplate\n",
    "few_shot_prompt = FewShotPromptTemplate(\n",
    "    examples=examples,\n",
    "    example_prompt=example_prompt,\n",
    "    prefix=\"按提示的格式，输出内容\",\n",
    "    suffix=\"输入：{input}\\n输出：\",  # 要放在示例后面的提示模板字符串。\n",
    "    input_variables=[\"input\"]  # 传入的变量\n",
    ")\n",
    "\n",
    "# 生成最终的 prompt\n",
    "print(few_shot_prompt.format(input=\"天津今天刮风吗\"))\n"
   ],
   "id": "323a08c2bd2923be",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "按提示的格式，输出内容\n",
      "\n",
      "输入：北京下雨吗\n",
      "输出：北京\n",
      "\n",
      "输入：上海热吗\n",
      "输出：上海\n",
      "\n",
      "输入：天津今天刮风吗\n",
      "输出：\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 4.2FewShotChatMessagePromptTemplate\n",
    "除了FewShotPromptTemplate之外，FewShotChatMessagePromptTemplate是专门为 聊天对话场景设计的少样本（few-shot）提示模板，它继承自 FewShotPromptTemplate ，但针对聊天消息的格式进行了优化。\n",
    "\n",
    "特点：\n",
    "\n",
    "自动将示例格式化为聊天消息（ HumanMessage / AIMessage 等）\n",
    "\n",
    "输出结构化聊天消息（ List[BaseMessage] ）\n",
    "\n",
    "保留对话轮次结构\n",
    "\n",
    "代码如下"
   ],
   "id": "8ae861e5c2c20cf3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-22T09:38:28.816477Z",
     "start_time": "2025-11-22T09:38:28.813016Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, FewShotChatMessagePromptTemplate\n",
    "\n",
    "# 定义示例数据，用于少样本学习\n",
    "# 包含输入输出对，展示乘法运算的格式和结果\n",
    "examples = [\n",
    "    {\"input\": \"1✖️2\", \"output\": \"2\"},\n",
    "    {\"input\": \"2✖️2\", \"output\": \"4\"},\n",
    "]\n",
    "\n",
    "# 创建示例提示模板，定义了人类提问和AI回答的交互格式\n",
    "# human消息使用\"{input}是多少\"的模板\n",
    "# ai消息使用\"{output}\"的模板\n",
    "example_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"human\", \"{input}是多少\"),\n",
    "    (\"ai\", \"{output}\"),\n",
    "])\n",
    "\n",
    "# 创建少样本聊天消息提示模板\n",
    "# 使用预定义的示例数据和示例提示模板\n",
    "# 该模板将用于在最终提示中提供上下文示例\n",
    "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "    examples=examples,\n",
    "    example_prompt=example_prompt,\n",
    ")\n",
    "\n",
    "# 构建最终的提示模板\n",
    "# 组合系统角色设定、少样本示例和用户问题\n",
    "# 系统设定AI为数学奇才，然后添加示例，最后是用户的具体问题\n",
    "final_prompt = (ChatPromptTemplate.from_messages(\n",
    "                [(\"system\", \"你是一名百年一遇的数学奇才\")])\n",
    "                + few_shot_prompt\n",
    "                + ChatPromptTemplate.from_messages([ (\"human\", \"{question}\"),])\n",
    ")\n",
    "\n",
    "# 格式化并打印最终提示模板，传入具体问题\"3✖️2\"\n",
    "print(final_prompt.format(question=\"3✖️2\"))"
   ],
   "id": "36d522727fa1e9f6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System: 你是一名百年一遇的数学奇才\n",
      "Human: 1✖️2是多少\n",
      "AI: 2\n",
      "Human: 2✖️2是多少\n",
      "AI: 4\n",
      "Human: 3✖️2\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 4.3Example selectors\n",
    "前面FewShotPromptTemplate的特点是，无论输入什么问题，都会包含全部示例。在实际开发中，我们可以根据当前输入，使用示例选择器，从大量候选示例中选取最相关的示例子集。\n",
    "\n",
    "使用的好处：避免盲目传递所有示例，减少 token 消耗的同时，还可以提升输出效果。\n",
    "\n",
    "示例选择策略：语义相似选择、长度选择、最大边际相关示例选择等\n",
    "\n",
    "语义相似选择：通过余弦相似度等度量方式评估语义相关性，选择与输入问题最相似的 k 个示例。\n",
    "\n",
    "长度选择：根据输入文本的长度，从候选示例中筛选出长度最匹配的示例。增强模型对文本结构的理解。比语义相似度计算更轻量，适合对响应速度要求高的场景。\n",
    "\n",
    "最大边际相关示例选择：优先选择与输入问题语义相似的示例；同时，通过惩罚机制避免返回同质化的内容。\n",
    "\n",
    "代码如下"
   ],
   "id": "904d553727e9dd59"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-22T09:46:32.172732Z",
     "start_time": "2025-11-22T09:46:30.782909Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.example_selectors import SemanticSimilarityExampleSelector\n",
    "from langchain_core.prompts import PromptTemplate, FewShotPromptTemplate\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "# 创建示例模板，用于格式化输入输出对\n",
    "example_prompt = PromptTemplate.from_template(template=\"Input:{input},Output:{output}\")\n",
    "\n",
    "# 定义示例数据集，包含输入词和对应的反义词\n",
    "examples = [\n",
    "    {\"input\": \"高\", \"output\": \"矮\"},\n",
    "    {\"input\": \"高兴\", \"output\": \"悲伤\"},\n",
    "    {\"input\": \"高级\", \"output\": \"低级\"},\n",
    "    {\"input\": \"高楼大厦\", \"output\": \"低矮茅屋\"},\n",
    "    {\"input\": \"高瞻远瞩\", \"output\": \"鼠目寸光\"}\n",
    "]\n",
    "\n",
    "# 初始化嵌入模型，用于将文本转换为向量表示\n",
    "embedding = OllamaEmbeddings(\n",
    "    model=\"qwen3-embedding:8b\"  # 或其他 embedding 模型\n",
    ")\n",
    "\n",
    "# 创建语义相似度示例选择器，用于根据输入选择最相似的示例\n",
    "# 该选择器使用FAISS向量数据库存储示例嵌入，并返回最相似的k个示例\n",
    "example_selector = SemanticSimilarityExampleSelector.from_examples(\n",
    "    examples,\n",
    "    embedding,\n",
    "    FAISS,\n",
    "    k=2,\n",
    ")\n",
    "\n",
    "# 创建少样本提示模板，结合示例选择器和提示模板生成最终提示\n",
    "# 该模板会根据输入选择相似示例，并按照指定格式组合成完整提示\n",
    "similar_prompt = FewShotPromptTemplate(\n",
    "    example_selector=example_selector,\n",
    "    example_prompt=example_prompt,\n",
    "    prefix=\"给出每个词语的反义词\",\n",
    "    suffix=\"输入:{input}\",\n",
    "    input_variables=[\"input\"]\n",
    ")\n",
    "\n",
    "# 格式化提示模板，将\"开心\"作为输入生成最终提示字符串\n",
    "prompt = similar_prompt.format(input=\"开心\")\n",
    "print(prompt)"
   ],
   "id": "39432fcc865ada45",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "给出每个词语的反义词\n",
      "\n",
      "Input:高兴,Output:悲伤\n",
      "\n",
      "Input:高级,Output:低级\n",
      "\n",
      "输入:开心\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 5.消息占位符提示词模板\n",
    "如果我们不确定消息何时生成，也不确定要插入几条消息，比如在提示词中添加聊天历史记忆这种场景，可以在ChatPromptTemplate添加MessagesPlaceholder占位符，在调用invoke时，在占位符处插入消息。"
   ],
   "id": "f6245fc71908a705"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 5.1使用MessagesPlaceholder",
   "id": "dace0852cabc15a1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-22T09:47:46.063460Z",
     "start_time": "2025-11-22T09:47:46.059880Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.messages import SystemMessage, HumanMessage, AIMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "# 构建一个 ChatPromptTemplate，包含多种消息类型：\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    # 插入 memory 占位符，用于填充历史对话记录（如多轮对话上下文）\n",
    "    MessagesPlaceholder(\"memory\"),\n",
    "\n",
    "    # 添加一条系统消息，设定 AI 的角色或行为准则\n",
    "    SystemMessage(\"你是一个资深的Python应用开发工程师，请认真回答我提出的Python相关的问题\"),\n",
    "\n",
    "    # 添加一条用户问题消息，用变量 {question} 表示\n",
    "    (\"human\", \"{question}\")\n",
    "])\n",
    "\n",
    "# 调用 prompt.invoke 来格式化整个 Prompt 模板\n",
    "# 传入的参数中：\n",
    "# - memory：是一组历史消息，表示之前的对话内容（多轮上下文）\n",
    "# - question：是当前用户的问题\n",
    "prompt_value = prompt.invoke({\n",
    "    \"memory\": [\n",
    "        # 用户第一轮说的话\n",
    "        HumanMessage(\"我的名字叫亮仔，是一名程序员\"),\n",
    "        # AI 第一轮的回应\n",
    "        AIMessage(\"好的，亮仔你好\")\n",
    "    ],\n",
    "    # 当前问题：结合上下文，测试模型是否记住了用户名字\n",
    "    \"question\": \"请问我的名字叫什么？\"\n",
    "})\n",
    "\n",
    "# 打印生成的完整 prompt 文本，格式化后的聊天记录\n",
    "print(prompt_value.to_string())\n"
   ],
   "id": "eba26eb958766560",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: 我的名字叫亮仔，是一名程序员\n",
      "AI: 好的，亮仔你好\n",
      "System: 你是一个资深的Python应用开发工程师，请认真回答我提出的Python相关的问题\n",
      "Human: 请问我的名字叫什么？\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 5.2隐式使用MessagesPlaceholder\n",
    "\"placeholder\" 是 (\"placeholder\", \"{memory}\") 的简写语法，等价于 MessagesPlaceholder(\"memory\")。"
   ],
   "id": "6c2c3ca675424521"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-22T09:48:21.382356Z",
     "start_time": "2025-11-22T09:48:21.379052Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 使用 ChatPromptTemplate 构建一个多角色对话提示模板\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    # 占位符，用于插入对话“记忆”内容，即之前的聊天记录（历史上下文）\n",
    "    (\"placeholder\", \"{memory}\"),\n",
    "\n",
    "    # 系统消息，用于设定 AI 的角色 —— 是一个资深的 Python 应用开发工程师\n",
    "    SystemMessage(\"你是一个资深的Python应用开发工程师，请认真回答我提出的Python相关的问题\"),\n",
    "\n",
    "    # 用户当前提问，使用变量 {question} 进行动态填充\n",
    "    (\"human\", \"{question}\")\n",
    "])\n",
    "\n",
    "# 使用 invoke 方法传入上下文变量，生成格式化后的对话 prompt 内容\n",
    "prompt_value = prompt.invoke({\n",
    "    # memory：是之前的对话上下文，会被插入到 {memory} 的位置\n",
    "    \"memory\": [\n",
    "        # 用户第一轮对话\n",
    "        HumanMessage(\"我的名字叫亮仔，是一名程序员\"),\n",
    "        # AI 第一轮回答\n",
    "        AIMessage(\"好的，亮仔你好\")\n",
    "    ],\n",
    "\n",
    "    # 当前的问题，将替换模板中的 {question}\n",
    "    \"question\": \"请问我的名字叫什么？\"\n",
    "})\n",
    "# 使用 .to_string() 将格式化后的对话链转换成纯文本字符串，方便查看输出\n",
    "print(prompt_value.to_string())\n"
   ],
   "id": "805d875e92c72596",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: 我的名字叫亮仔，是一名程序员\n",
      "AI: 好的，亮仔你好\n",
      "System: 你是一个资深的Python应用开发工程师，请认真回答我提出的Python相关的问题\n",
      "Human: 请问我的名字叫什么？\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 6.提示词模板仓库\n",
    "LangChain Hub 是一个公共的 prompt（提示词）仓库，访问地址是https://smith.langchain.com/hub。类似 HuggingFace Hub，但是专门存放 LangChain 的 Prompt、Chains、Tools 等。我们可以在 hub 中搜索通用的提示词模板并使用。\n",
    "\n",
    "代码如下："
   ],
   "id": "d607babb9bfe63bf"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-22T09:48:53.708867Z",
     "start_time": "2025-11-22T09:48:47.983499Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain import hub\n",
    "\n",
    "prompt = hub.pull(\"hwchase17/openai-tools-agent\")\n",
    "\n",
    "# 查看结构（Langchain PromptTemplate 的 repr）\n",
    "print(prompt)\n",
    "\n",
    "# 或者访问具体字段\n",
    "print(prompt.messages)"
   ],
   "id": "ede4b7863720ba50",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['agent_scratchpad', 'input'] optional_variables=['chat_history'] input_types={'chat_history': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x000002570B3DB740>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]], 'agent_scratchpad': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x000002570B3DB740>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]]} partial_variables={'chat_history': []} metadata={'lc_hub_owner': 'hwchase17', 'lc_hub_repo': 'openai-tools-agent', 'lc_hub_commit_hash': 'c18672812789a3b9697656dd539edf0120285dcae36396d0b548ae42a4ed66f5'} messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are a helpful assistant'), additional_kwargs={}), MessagesPlaceholder(variable_name='chat_history', optional=True), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={}), MessagesPlaceholder(variable_name='agent_scratchpad')]\n",
      "[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are a helpful assistant'), additional_kwargs={}), MessagesPlaceholder(variable_name='chat_history', optional=True), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={}), MessagesPlaceholder(variable_name='agent_scratchpad')]\n"
     ]
    }
   ],
   "execution_count": 26
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
